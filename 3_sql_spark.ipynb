{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c91c06b-27e1-4559-8b9f-42df30566d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.5.1\n",
      "  Using cached pyspark-3.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark==3.5.1) (0.10.9.7)\n",
      "Installing collected packages: pyspark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.5.0\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11d42628-0495-4b0c-9d43-1d36d52d4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, broadcast, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import pytz\n",
    "\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17eac5ee-7753-4b8d-bba1-1f659d872e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.19.0.4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "# проверка доступности namenode\n",
    "socket.gethostbyname(\"namenode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38db8ae-3b21-4acd-ad85-96d24a501c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark/python\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e978c99d-b6e6-402f-9083-0dac59d15de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n",
      "openjdk version \"17.0.8.1\" 2023-08-24\n",
      "OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b0736a-057e-41a2-a927-f75c3341ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://13cabd641c45:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HDFS Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x79f3c8b54910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HDFS Project\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c099526-4ebb-4015-9ad8-f8d1a2556fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные из файла-\"паркета\"\n",
    "df = spark.read.parquet(\"hdfs://namenode:9000/data/covid_dataset/metadata/metadata.parquet\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "249ebf20-6f66-4b66-bb6d-609022511425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем таблицу с партиционирование и бакетирование и сохраняем в нее данные\n",
    "(\n",
    "    df    \n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"parquet\")\n",
    "    .partitionBy(\"finding\")\n",
    "    .bucketBy(5, \"sex\",\"age\")    \n",
    "    .saveAsTable(\"tbl_covid\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ed71548-6614-48c5-b444-b637e0f1079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Либо можно было напрямую запросом создать таблицу\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS tbl_covid (\n",
    "    patientid INT,\n",
    "    offset INT,\n",
    "    sex INT,\n",
    "    age INT,\n",
    "    RT_PCR_positive INT,\n",
    "    survival INT,\n",
    "    intubated INT,    \n",
    "    intubation_present INT,\n",
    "    went_icu INT,\n",
    "    in_icu INT,\n",
    "    needed_supplemental_O2 INT,\n",
    "    temperature INT,\n",
    "    pO2_saturation INT,\n",
    "    leukocyte_count INT,\n",
    "    neutrophil_count INT,\n",
    "    lymphocyte_count INT,\n",
    "    folder STRING,\n",
    "    filename STRING,\n",
    "    sick INT,\n",
    "    age_group STRING\n",
    ")\n",
    "PARTITIONED BY (finding STRING)\n",
    "CLUSTERED BY (age,sex) INTO 5 BUCKETS\n",
    "STORED AS PARQUET\n",
    "\"\"\"\n",
    "\n",
    "# Выполняем запрос\n",
    "#spark.sql(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47504062-3a5d-468a-82c5-58551b752d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверяем, что данные есть в таблице\n",
    "df_tbl = spark.table(\"tbl_covid\")\n",
    "\n",
    "df_tbl.filter(\"finding = 'covid'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1dc7cab-c3c8-464b-9c1a-2f83d847e177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|     finding|count(1)|\n",
      "+------------+--------+\n",
      "|       covid|     314|\n",
      "|   pneumonia|     112|\n",
      "|tuberculosis|      11|\n",
      "|          no|       9|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обязательно включить запрос с оконными функциями;\n",
    "# использовать сложные соединения таблиц;\n",
    "# применить аналитические подзапросы.\n",
    "\n",
    "# Набор данных (количество строк),да и самих столбцов не велик, поэтому запросы придуманы очень синтетические\n",
    "# 1. Количество заболевших с группировкой по заболеванию\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        finding, count(*)\n",
    "FROM tbl_covid\n",
    "    GROUP BY finding\n",
    "    ORDER BY count(*) desc\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97181ad5-1b19-41b0-ab62-c5a7e0538345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---+----------------+------------------+\n",
      "|patientid| age|sex|lymphocyte_count|lymphocyte_ranking|\n",
      "+---------+----+---+----------------+------------------+\n",
      "|      200|88.0|1.0|           131.0|                 1|\n",
      "|      314|21.0|1.0|            10.1|                 2|\n",
      "|      242|24.0|1.0|             2.9|                 3|\n",
      "|      248|24.0|1.0|             2.8|                 4|\n",
      "|      230|24.0|1.0|             2.7|                 5|\n",
      "|      223|24.0|1.0|             1.8|                 6|\n",
      "|      149|40.0|1.0|            1.73|                 7|\n",
      "|      227|24.0|0.0|             1.6|                 8|\n",
      "|      245|24.0|1.0|             1.4|                 9|\n",
      "|      148|41.0|1.0|             1.3|                10|\n",
      "|      228|24.0|0.0|             1.2|                11|\n",
      "|       94|31.0|0.0|             1.2|                11|\n",
      "|      240|24.0|1.0|             1.1|                13|\n",
      "|      256|24.0|1.0|             1.1|                13|\n",
      "|      246|24.0|1.0|             1.0|                15|\n",
      "|       12|42.0|1.0|             0.9|                16|\n",
      "|      237|24.0|0.0|             0.8|                17|\n",
      "|      472|47.0|1.0|             0.8|                17|\n",
      "|       72|60.0|1.0|             0.8|                17|\n",
      "|      329|34.0|1.0|           0.762|                20|\n",
      "+---------+----+---+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ранжирование пациентов по параметру lymphocyte_count в обратном порядке\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        patientid, age, sex, lymphocyte_count,\n",
    "        RANK() OVER(ORDER BY lymphocyte_count desc) as lymphocyte_ranking\n",
    "FROM tbl_covid\n",
    "WHERE lymphocyte_count is not null\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f837f8f-9da1-4263-8281-06d5007fab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----+---+------+---------+----------------------+-----------------+-----------------+\n",
      "|Patient_A|Patient_B| age|sex|in_icu|intubated|needed_supplemental_O2|Survival_Status_A|Survival_Status_B|\n",
      "+---------+---------+----+---+------+---------+----------------------+-----------------+-----------------+\n",
      "|       13|     326b|35.0|1.0|   0.0|      0.0|                   1.0|         Survived|         Deceased|\n",
      "|      336|     326b|49.0|1.0|   1.0|      0.0|                   1.0|         Survived|         Deceased|\n",
      "|       19|     326b|55.0|0.0|   0.0|      0.0|                   1.0|         Survived|         Deceased|\n",
      "|      349|     326b|57.0|1.0|   0.0|      0.0|                   1.0|         Survived|         Deceased|\n",
      "|        2|     326b|65.0|1.0|   0.0|      0.0|                   1.0|         Survived|         Deceased|\n",
      "|     326b|      349|94.0|1.0|  NULL|      0.0|                   1.0|         Deceased|         Survived|\n",
      "|     326b|      336|94.0|1.0|  NULL|      0.0|                   1.0|         Deceased|         Survived|\n",
      "|     326b|       13|94.0|1.0|  NULL|      0.0|                   1.0|         Deceased|         Survived|\n",
      "|     326b|        2|94.0|1.0|  NULL|      0.0|                   1.0|         Deceased|         Survived|\n",
      "|     326b|       19|94.0|1.0|  NULL|      0.0|                   1.0|         Deceased|         Survived|\n",
      "+---------+---------+----+---+------+---------+----------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Найдем пациентов с одним диагнозом, получившим аналогичные вмешательства (например, интубацию и кислородотерапию),\n",
    "# но один выжил, а другой нет, и выяснить, как эти факторы повлияли на выживаемость.\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    T1.patientid AS Patient_A,\n",
    "    T2.patientid AS Patient_B,\n",
    "    T1.age,\n",
    "    T1.sex,\n",
    "    T1.in_icu,\n",
    "    T1.intubated,\n",
    "    T1.needed_supplemental_O2,\n",
    "    CASE\n",
    "        WHEN T1.survival = 1 THEN 'Survived'\n",
    "        ELSE 'Deceased'\n",
    "    END AS Survival_Status_A,\n",
    "    CASE\n",
    "        WHEN T2.survival = 1 THEN 'Survived'\n",
    "        ELSE 'Deceased'\n",
    "    END AS Survival_Status_B\n",
    "FROM\n",
    "    tbl_covid T1\n",
    "JOIN\n",
    "    tbl_covid T2\n",
    "ON\n",
    "    T1.finding = T2.finding  -- одинаковые диагнозы\n",
    "    AND T1.patientid <> T2.patientid  -- исключаем совмещение пациента с самим собой\n",
    "    AND T1.intubated = T2.intubated  -- интубация проведена у обоих пациентов\n",
    "    AND T1.needed_supplemental_O2 = T2.needed_supplemental_O2  -- нуждалась ли терапия кислородом\n",
    "WHERE\n",
    "    T1.survival <> T2.survival  -- пациенты с разной судьбой (один выжил, другой погиб)\n",
    "ORDER BY\n",
    "    T1.age;\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b66b3f44-e0d1-4f11-9cfe-7af32ea20ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Обработка в PySpark.\n",
    "# Фильтрация снимков с определенным диагнозом и сохранение результатов в Parquet:\n",
    "# выбрать подмножество данных по определенному критерию (например, только пациенты с диагнозом COVID-19);\n",
    "# сохранить результат в оптимизированном формате (Parquet/ORC) в HDFS.\n",
    "\n",
    "df_spark = spark.sql(\"SELECT * FROM tbl_covid\")\n",
    "# Фильтруем пациентов с положительным результатом на COVID-19\n",
    "filtered_df = df_spark.filter(df_spark.finding == 'covid')\\\n",
    "                .select(\"patientid\", \"sex\", \"age\", \"finding\", \"survival\", \"temperature\", \"leukocyte_count\", \"lymphocyte_count\")\n",
    "\n",
    "# Сохраняем результат в HDFS в формате Parquet\n",
    "filtered_df.write.parquet(\"output/spark_filter1.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c4f26fb-953f-409f-9cb4-5849e80abce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование UDF (пользовательских функций):\n",
    "def categorize_age(age):\n",
    "    if age < 30:\n",
    "        return \"young\"\n",
    "    elif age <= 60:\n",
    "        return \"middle\"\n",
    "    else:\n",
    "        return \"old\"\n",
    "\n",
    "# Регистрация UDF\n",
    "categorize_age_udf = udf(categorize_age, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3f1525c-8fed-4db2-8c8b-76077b3a629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция унификации диагноза\n",
    "# !!! На предыдущих шагах сделал уже унификацию, поэтому формально функцию реализовываю\n",
    "def unify_finding(finding):\n",
    "    if finding.startswith(\"COVID-19\"):\n",
    "        return \"COVID-19\"\n",
    "    return finding\n",
    "\n",
    "# Регистрация UDF\n",
    "unify_finding_udf = udf(unify_finding, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a52c184-5eaf-48c7-a81f-0debf4459134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем UDF\n",
    "processed_df = df_spark \\\n",
    "                        .withColumn(\"age_category\", categorize_age_udf(df_spark.age)) \\\n",
    "                        .withColumn(\"finding_unified\", unify_finding_udf(df_spark.finding)) \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecc8831e-fe4c-4b76-9e75-83798ba1cc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----+---------------+--------+---------+------------------+--------+------+----------------------+-----------+--------------+---------------+----------------+----------------+------------+--------------------+----+---------+-----------------+-------+------------+---------------+\n",
      "|patientid|offset| sex| age|RT_PCR_positive|survival|intubated|intubation_present|went_icu|in_icu|needed_supplemental_O2|temperature|pO2_saturation|leukocyte_count|neutrophil_count|lymphocyte_count|      folder|            filename|sick|age_group|__index_level_0__|finding|age_category|finding_unified|\n",
      "+---------+------+----+----+---------------+--------+---------+------------------+--------+------+----------------------+-----------+--------------+---------------+----------------+----------------+------------+--------------------+----+---------+-----------------+-------+------------+---------------+\n",
      "|       19|  27.0| 0.0|55.0|            1.0|     1.0|      0.0|               0.0|     0.0|   0.0|                   1.0|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|1-s2.0-S092966462...|   1|   middle|               46|  covid|      middle|          covid|\n",
      "|      252|  27.0| 0.0|24.0|            0.0|    NULL|     NULL|              NULL|     0.0|   0.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|        c601f50d.jpg|   1|    young|              476|  covid|       young|          covid|\n",
      "|       67|  25.0|NULL|24.0|            1.0|     1.0|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|1-s2.0-S168411822...|   1|    young|              130|  covid|       young|          covid|\n",
      "|      250|  24.0| 0.0|24.0|            0.0|     1.0|     NULL|              NULL|     1.0|   0.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|        db96a050.jpg|   1|    young|              471|  covid|       young|          covid|\n",
      "|       68|  19.0|NULL|24.0|            1.0|     1.0|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|1-s2.0-S168411822...|   1|    young|              132|  covid|       young|          covid|\n",
      "|      224|  16.0| 0.0|24.0|            0.0|    NULL|     NULL|              NULL|     0.0|   0.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|        a38e1877.jpg|   1|    young|              425|  covid|       young|          covid|\n",
      "|       17|  15.0| 1.0|54.0|            1.0|     1.0|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|jkms-35-e79-g001-...|   1|   middle|               38|  covid|      middle|          covid|\n",
      "|      194|  14.0| 1.0|64.0|            0.0|    NULL|      1.0|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|          paving.jpg|   1|      old|              343|  covid|         old|          covid|\n",
      "|      222|  13.0| 0.0|24.0|            0.0|     1.0|     NULL|              NULL|     1.0|   0.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|        87d50e40.jpg|   1|    young|              423|  covid|       young|          covid|\n",
      "|      235|  12.0| 0.0|24.0|            0.0|     1.0|     NULL|              NULL|     1.0|   0.0|                  NULL|       NULL|          45.0|           NULL|            NULL|            NULL|images/covid|        3dedeb92.jpg|   1|    young|              442|  covid|       young|          covid|\n",
      "|      151|  12.0|NULL|24.0|            1.0|    NULL|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|radiol.2020201160...|   1|    young|              269|  covid|       young|          covid|\n",
      "|      187|  12.0| 1.0|50.0|           NULL|     0.0|      1.0|               0.0|     1.0|  NULL|                   1.0|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|yxppt-2020-02-19_...|   1|   middle|              332|  covid|      middle|          covid|\n",
      "|      113|  10.0|NULL|24.0|            0.0|    NULL|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|1.CXRCTThoraximag...|   1|    young|              211|  covid|       young|          covid|\n",
      "|      154|  10.0|NULL|24.0|            1.0|    NULL|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|radiol.2020201160...|   1|    young|              272|  covid|       young|          covid|\n",
      "|       73|  10.0| 0.0|24.0|            1.0|     1.0|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|41591_2020_819_Fi...|   1|    young|              143|  covid|       young|          covid|\n",
      "|      173|  10.0| 0.0|70.0|            1.0|    NULL|      1.0|               1.0|     1.0|   1.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|covid-19-pneumoni...|   1|      old|              307|  covid|         old|          covid|\n",
      "|       55|  10.0| 1.0|87.0|            1.0|    NULL|     NULL|              NULL|    NULL|  NULL|                  NULL|       95.0|          NULL|           NULL|            NULL|            NULL|images/covid|7E335538-2F86-424...|   1|      old|              108|  covid|         old|          covid|\n",
      "|       32|   7.0| 1.0|43.0|            1.0|    NULL|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|DE488FE1-0C44-428...|   1|   middle|               71|  covid|      middle|          covid|\n",
      "|      112|   7.0|NULL|24.0|            0.0|     1.0|     NULL|              NULL|    NULL|  NULL|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|1.CXRCTThoraximag...|   1|    young|              209|  covid|       young|          covid|\n",
      "|       37|   7.0| 1.0|58.0|            0.0|    NULL|      1.0|               1.0|     1.0|   1.0|                  NULL|       NULL|          NULL|           NULL|            NULL|            NULL|images/covid|31BA3780-2323-493...|   1|   middle|               85|  covid|      middle|          covid|\n",
      "+---------+------+----+----+---------------+--------+---------+------------------+--------+------+----------------------+-----------+--------------+---------------+----------------+----------------+------------+--------------------+----+---------+-----------------+-------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9bd9213-6239-4189-8a4b-8e033cd7d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
